

%This thesis describes   exploit explicit datapaths in an LLVM-based compiler for an ultra-wide SIMD architecture.

%TODO: rewrite this in my own words
%This thesis describes the development of an LLVM-based compiler for a wide SIMD architecture. In this chapter, the motivation of this thesis is described, together with the generic features of a wide SIMD architecture. Then, the problems of the existing compiler, and the final goal are introduced in the problem statement. The thesis overview shows the structure and basic information of each chapter in this report.

Embedded systems are everywhere, over ninety percent of all microprocessors are manufactured as components of embedded systems.
Never have we had such growth in the use of such embedded devices. Nowadays, most people carry a mobile phone that is more powerful than the computer I played my first game on in `98. %A: no newline. Q: decide if new paragraph?
Many embedded systems, like mobile phones, have to run high-performance applications, like wireless signal processing and 3D vision processing \cite{dongrio1}, which could be made possible by powerful processors (ARM64 / AArch64) that run at high clock speeds. However, these kinds of mobile devices often have a limited energy source, and because they are often handheld devices heat produced by power dissipation is also of concern. As embedded applications become more and more complex and are adopting more sophisticated algorithms, the issues of their computing performance and energy efficiency become more and more serious. To address their issues dedicated processors are developed for different kinds of embedded applications, like video/image processing, deep learning, and other advanced algorithms \cite{lechjozwiak}.

% TODO: use Lech's paper !!!!!!!!
%brugzin Luc
The dissertation by Dongrui et. al. \cite{dongrui} aims to address these concerns, by investigating a low energy configurable programmable platform implementing an ultra-wide \emph{Single Instruction Multiple Data} (SIMD) architecture. In general, a wide SIMD architecture consists of a \emph{Control Processor} (CP) that runs in parallel with a wide array of \emph{Processing Elements} (PEs). The CP is responsible for scalar operations and the control flow, while the PE array executes a single instruction on multiple data. Because the PEs execute the same instruction in each cycle, the instruction fetch and decode can be shared among the PEs. Therefore, the energy consumed by these parts is distributed over multiple PEs and becomes negligible. For certain kernels, it can exploit parallelism by processing multiple operations in parallel instead of processing them sequentially. Therefore, the required throughput can be achieved at a substantially lower clock frequency and thus lower voltage, thereby greatly reducing energy consumption and power dissipation \cite{dongrio2}.% (power is proportional to the clock frequency). 
%een techniek om energie nog verder te optimaliseren, door bypassen van je rf, en dat kan automatisch en explicit, en in dit geval kijken we naar expliciet.

%to program these kind of architectures / bruggetje
To program these kind of architectures, an architecture specific compiler has to be build. Compilers are indispensable for high-level language to executable code translation, but have also a significant role in the design of computer architectures. During the design phase of an architecture, one may want to see how efficient such design is or what impact certain design decisions have. To analyze how efficient applications can execute on a design, we need a compiler to translate an application to machine code, which is then used to simulate the execution of such architecture. The combination of a processor architecture, a high-level application code, and compiler for this architecture decide the quality of a resulting hardware/software system. Therefore, architecture design and compiler development go hand in hand.  

The \emph{Electronic Systems} (ES) group at the \emph{Eindhoven University of Technology} (TU/e) is doing research in a wide SIMD with low energy features in order to achieve a programmable platform configurable for specific applications for a high energy efficiency \cite{dongrio1}. The current compiler for this platform is developed completely within the LLVM framework, but does not generate code for explicit datapaths. However, there is an older version of the compiler, which we refer to as the legacy compiler that does generate code for explicit datapaths. It uses LLVM's front-end with a custom back-end that has limited maintainability and is stuck to an old version of LLVM's front-end, therefore, not benefiting from developments in the field of compilers.

%\newpage 
\section{Motivation}
This master thesis aims at completing the transition to LLVM such that the developed compiler supports all design options including explicit datapaths. %avoid mentioning the compiler course, just mention that compilers are 'vet handig'.
We would highly benefit from having a fully functional SIMD compiler in LLVM. There are compiler developers working around the clock on many different architectures, e.g. xCORE\footnote{www.xmos.com/products/silicon} (multicore microcontrollers), AArch64 (mobile phones) and x86 (modern computers). With an LLVM-based compiler, we benefit from developments on LLVM and greatly improve maintainability of the compiler.

We will measure the efficiency of the generated code for a very low energy ultra wide SIMD architecture in terms of code quality and energy efficiency. A practical LLVM-based compiler is compared to a legacy custom build compiler and efficiency is assessed using handwritten assembly code references. We want to know to what degree low power this architecture truly is and see if we can make a successful transition to LLVM. Many companies have standardized to LLVM already, and we compare our LLVM compiler to a legacy custom build compiler. %TODO: rewrite this paragraph

This work also focusses on improving the energy efficiency by implementing a specific optimization technique to reduce communication with the \emph{register file} (RF). The RF is one of the most power-hungry, and often used components in a processor. 

We analyze the gain in energy efficiency by exploiting explicit datapaths. The SIMD architecture has busses that contain time-dependent values of results of the functional units. Accessing one of these busses is cheaper than accessing a register file in terms of energy. Therefore, we use communication involving these buses to decrease the traffic involving the register file. Thereby, improving energy efficiency. 

% Research to energy efficient other approaches Shafflic and emb. sys. abstract barry.

\section{Problem Statement}\label{sec:problem_statement}
For the architecture at hand, several features were selected to be considered. Each combination of values for these features results in a different hardware configuration:
\begin{itemize}
\item \textbf{Processor pipelining} is the technique to split the task of a processor up in multiple steps. Because the processor works on different steps at the same time, more instruction can be executed and thereby increasing throughput. A four-stage or five-stage pipeline can be chosen. %We use pipelining (where each stage takes one clock cycle). We can choose a four-stage or a five-stage pipeline design.
\item	\textbf{Bit-width of the data} that the processor operates on is configurable to 32 or 16 bits. With smaller 16-bit you may further improve energy efficiency, but requires knowledge of the programmer and consideration during application development. The 32-bit data width may be sufficient for embedded applications but is still smaller than 64-bit architectures.
\item	\textbf{Extension of the \emph{Instruction Set Architecture} (ISA)} has also been considered. For example, it may be beneficial to have a  \emph{Functional Unit} (FU) that can do multiply-accumulate instructions for, e.g. signal processing filters, like \emph{Finite Impulse Response} (FIR) filters, linear algebra, like matrix multiplication, and \emph{Convolutional Neural Networks} (CNN). %TODO: find and fix comma misuse within clauses
\item \textbf{Explicit or implicit bypassing} can be implemented in the processor. These features reduce accesses to register files by result forwarding (which is discussed in Chapter \ref{sec:datapaths}), and dead result elimination with explicit bypassing. With implicit, also called automatic bypassing, dedicate hardware detects and exploits these bypasses. With explicit bypassing, it is the responsibility of the compiler to exploit them.
\end{itemize}

In general, it is desired to have a compiler that satisfies some basic requirements, (i) it should be easy to maintain, (ii) it should be easy to add other features and (iii) it should produce high-quality code. Of course, it should always generate a correct code.

The legacy compiler has some input language limitations, maintenance problems and 
does not always generate a correct code.
\begin{itemize}
\item \textbf{Input Language Limitations:} One needs to implement an application in OpenCL to get vectorized code. Moreover, it only supports a subset of the OpenCL language. Altogether, this puts the responsibility on the programmer which is something that we want to avoid. Furthermore, the generated code is not vectorized when C code is used as input language. 
\item \textbf{Maintenance:} The back-end of the legacy compiler is too custom and, maintainability would benefit from standardization. Namely, because it is difficult to implement new features and not all considered features have been developed.   
\end{itemize}

The practical LLVM-based compiler has drastically improved maintainability and uses LLVM's auto-vectorizer to generate vector instructions. Compared with the old compiler, the new compiler is more flexible and supports a large number of input languages. The optimization passes supplied by LLVM also improve the quality of the generated code. Furthermore, developments on LLVM make it easy to update the compiler and can, therefore, benefit from developments in compiler technologies. However, the new compiler does not support all features. Namely, it can only generate code for a target machine with four pipeline stages, implicit datapaths, and a bit-width of 32 bits. We will maintain and add features to the new compiler with a focus on the exploration of explicit datapaths.

This master thesis aims at completing the transition to LLVM such that the developed compiler supports all design options including explicit datapaths

%TODO: vraag : een hoop werk om een zin te zeggen haha moet hier nog iets volgen? moet hier nog iets na komen
The main problem is ``How to generate efficient code for SIMD that exploits explicit datapaths?". 

%is no support for a five stage pipeline configuration and only implicit datapaths have been considered.  
%TODO: ask : completely avoid hardware generation? or mention? that current implementation does allow many of these features and configurabilities, but consists of multiple implementations and has too much code duplication.

% So for that reason we have maintained the compiler additional to developing the compiler requirements of this thesis.
%\section{Contributions}
%This thesis onderzoek gedaan naar een compiler voor llvm voor een architectuur dat is designed by the TU/e. We aim to having a fully functional compiler that is implemented in LLVM. The compiler course is a course where students are introduced in compiler technologies and this relatively easy to understand architecture can help student to get introduced in LLVM. There are developers working around the clock on other architectures, e.g. xCORE (multicore microcontrollers), x86 (nowadays computers) (link to www.xmos.com/products/silicon) and AArch64 (mobile phones). Having knowledge on LLVM may help these students to improve their knowledge on such computer architectures.  

%I aim to provide research in efficiency of explicit datapaths for our ultra low power SIMD architecture. In general, I will consider different approaches to exploit them within LLVM and add this functionality to the compiler. For practical use, this architecture could be used as accelerator or off-the-shelf module or even embedded processor for certain applications. extension, 

\section{Thesis Overview}


The next chapter describes background information that will provide key information to this thesis, including a basic introduction to LLVM, an overview of the SIMD architecture and related work.

Chapter \ref{chapter:compiler} discusses LLVM-based code generation for our target architecture with a focus on explicit datapaths, followed by an evaluation in Chapter \ref{chapter:evaluation}. Future work %in Chapter \ref{sec:future_work} 
is presented before concluding in Chapter \ref{chapter:conclusion}.

%This thesis is organized as follows.  Chapter \ref{chapter:compiler} is devoted to LLVM-based code generation for SIMD with focus on explicit datapaths. Chapter \ref{chapter:evaluation} gives evaluations and preliminary conclusions. Chapter \ref{chapter:conclusion} concludes and gives any future work. 