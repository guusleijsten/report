There is related work for compilers that target SIMD architectures, in particular, a compiler has been developed, referred to as legacy compiler. Furthermore, there is related work in building an LLVM backend, and compiling with explicit data paths has been an active research topic for other architectures. We will also discuss some related work in scheduling and register allocation. We have divided this in four section in the remainder of this chapter.
% scrap
%The related work is introduced in this part, including the legacy compiler, building the LLVM back-end for SIMD architecture, explicit datapaths in other architecture and some scheduling and register allocation algorithms applied in other compilers.

\section{Legacy compiler}
The legacy compiler was developed by the ES group in 2003. We will use the SIMD architecture as it was designed during that project \cite{simd}. The legacy compiler has a custom backend for the SIMD architecture, that can generate code for explicit data paths \cite{dongrio1} and it can only compile a subset of C code and hand-touched OpenCL code, which requires manual insertion of custom pragmas to compile efficiently \cite{dongrio2}, which we do not desire. Our goal is to overcome these limitations and improve the compilers maintainability. Furthermore, the new compiler will be evaluated relative to the legacy compiler in order to access efficiency of the generated code.
%Dongrio's simd work 
%Johan janssen & ... TTA work
%Other exposed datapaths

\section{Building an LLVM back-end}
Our backend is derived from tricore tutorial on creating a new backend for the LLVM compiler framework \cite{tricore}. Furthermore, based on that work, an LLVM backend for SIMD architecture without explicit bypassing has been developed \cite{liu_zhenyuan}. However, the current compiler generates code with implicit bypassing. We, therefore, need to extend this to efficiently generate code for explicit bypassing as well. Therefore, our work will be an extension to previously noted work.

\section{Other Exposed/Explicit Datapath Architectures}
Compiling with explicit data,paths have been an active topic of research. We have investigated several architectures that face similar challenges. One of the main works that we investigated is the TTA architecture, where instructions consist of data transports. However, their approach can not be used because with our SIMD architecture, data transports are given and we want to compile in order to efficiently use the explicit data paths that are provided \cite{tta, tta_codegen}.

Another architecture that exploits explicit datapath architectures is the ReMove architecture \cite{remove}. That work focusses on scheduling for partially connected architectures with explicit data paths. The ReMove architecture is similar to a VLIW, having multiple FUs, however here they have an interconnect network that connects the FUs to the RF. The scheduling algorithm used in this work can not be used in our work, because similar to the legacy compiler for SIMD, this project has a custom backend, which can not be reused for LLVM. However, the basic principles of the scheduling algorithms proposed in this work are still valid and may be reused for our work.

\section{Scheduling and Register Allocation}
First of all, from the existing scheduling algorithms, Swing Modulo Scheduling (SMS) seems to be a suitable scheduling approach. It is a heuristic approach that is able to deal efficiently with software pipelining. Furthermore, it is known for its outstanding performance and low computational cost. The generated schedules are near optimal in terms of initiation interval and register requirements \cite{swingmodulo_paper, swingmodulo_thesis}. We consider this a candidate scheduler to use.

Furthermore, the following literature discusses register allocation for SSA-based programs that solves coloring problem optimally in quadratic-time optimal by decoupling coloring, spilling and coalescing \cite{ra}. This technique may allow us to implement a custom register allocator that solves the problem in polynomial time.

Finally, there is another project, called Unison. They solve scheduling and register allocation and other code generation tasks by translating them into combinatorial problems and solve them together with constraint programming \cite{unison}. We consider this a candidate constraint solver to use because it can be easily integrated with LLVM.