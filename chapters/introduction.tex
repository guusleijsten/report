Nowadays, mobile phones have dedicated processors to support video processing. This embedded streaming processor consumes tens of pJ per operation (pJ/op) and the battery capacity is only sufficient for playing video applications for a few hours \cite{simd}.
Furthermore, embedded systems like mobile devices have to run high performance applications like video encoding/decoding, wireless signal processing and 3D processing \cite{dongrio1}. These kind of devices often have a limited energy source, and because it is a handheld device, heat produced by power dissipation is another concern. For these reasons, energy efficiency is becoming the bottleneck in the design of such embedded systems.

In general, it is important to improve both performance and energy efficiency. The Very Long Instruction Word (VLIW) architecture is one example architecture designed to improve performance by executing multiple instructions in parallel, exploiting a program's Instruction Level Parallelism (ILP). By exploiting parallelism, the processor requires less cycles to do the same amount of work, thereby improving performance. 

The Transport Triggered Architecture (TTA) is similar to the VLIW architecture. However, instead of packing the operations in a single instruction, TTAs pack multiple transports in a single instruction \cite{tta}. For traditional VLIWs, each Register File (RF) is connected to every Function Unit (FU). Unlike VLIW, TTAs do not require that each FU has their own private connections to the RFs. Instead, an FU is connected to the RF by means of an interconnect. Another advantage that TTA has over VLIW is that it has explicit datapaths. With explicit datapaths, software bypassing is possible. The compiler can eliminate some RF accesses, which improves energy efficiency.

%TODO: Make link between explicit bp and compiler support.

Image and video processing applications typically have a high amount of Data Level Parallelism (DLP). The advantage of the Single Instruction Multiple Data (SIMD) architecture is that it naturally exploits DLP by processing multiple operations in parallel instead of processing them sequentially. Therefore, the same performance can be achieved at a much lower clock frequency, thereby reducing energy consumption \cite{dongrio1}. Furthermore, the instruction fetch and decode energy is shared amongst the processing elements. This improves energy efficiency with respect to an architecture that has an instruction fetch and decode for each processing unit, e.g. VLIW. A common bottleneck to achieve even higher energy efficiency with SIMD are the register files that consume a large amount of energy every time they are accessed. This work focusses on improving the energy efficiency by reducing accesses to the register files.

The proposed SIMD architecture has many processing elements that each have their own register file. This sums up to many register files that consume around 34.6\% of the total energy consumption \cite{dongrio1}. To further reduce energy consumption, we add explicit bypassing on top of the SIMD in order to eliminate some RF accesses. Adding explicit bypassing on top of the SIMD architecture resembles the TTA. Namely SIMD with explicit bypassing has an explicit datapath, like TTA also has an explicit datapath.

In the past, a compiler for the proposed architecture has already been implemented. This compiler exploits explicit bypassing \cite{dongrio1} and can compile a subset of OpenCL and C code \cite{dongrio2}. However, this compiler has a custom backend, and in order to standardize and improve maintainability, we want to use a compiler framework that supports our needs. To this end we use the LLVM framework to design and build a compiler for the proposed SIMD architecture.

%%%%%%%%%%OTHER PROEJCTS IN THIS SIMD, INCOMPLETE NOT CONTRIBUTING......
%This master project is part of a bigger project in which we work on the architecture and its compiler. There is another master's project going on about writing a compiler for the proposed SIMD architecture using the LLVM framework \cite{liu_zhenyuan}. However, this compiler focusses on vector instructions and does not support explicit bypassing. Therefore, we will focus on adding explicit bypassing on top of the new compiler. Furthermore, the proposed SIMD architecture is designed to be configurable. Another master's project will investigate in how to generate hardware code for different combinations of parameters.% \cite{boyan_liang}.

In the remainder of this chapter, first the target SIMD architecture is discussed in Chapter \ref{sec:simd}. Then we will introduce the reader to the LLVM compiler framework in Chapter \ref{sec:llvm}. We will give a more concrete statement of the problem in Chapter \ref{sec:problem_statement}. Finally, we will give an overview of the remainder of this report in Chapter \ref{sec:overview}.

\section{The SIMD Processor Architecture}\label{sec:simd}
\input{chapters/simd}

\section{The LLVM Compiler Framework}\label{sec:llvm}
\input{chapters/llvm}

%Problem statement -> incorporate Roel's Feedback..!!!
\section{Problem statement}\label{sec:problem_statement}
An SIMD architecture has been designed and a legacy compiler exists. However, the legacy compiler is too custom and therefore difficult to maintain. Many optimizations still have to be implemented. One of the advantages of LLVM is that a large community works on it. Many optimizations are already in place and can immediately be used for our compiler. Standardizing and having proper tool support improves maintainability of the compiler. %Namely, anyone familiar with LLVM can now understand and improve the compiler.
For this reason, a new compiler is being implemented in LLVM.

We have a new compiler in LLVM that supports vector operations and can compile any IR code into SIMD specific assembly. The legacy compiler does have support for explicit bypassing. We want to develop explicit bypassing in the new compiler structure.

The goal of this project is therefore to generate efficient code to support explicit bypassing. We have separated the goal in multiple research questions:

\begin{enumerate}
\item How do we implement explicit bypassing within LLVM?

How does this fit in the new compiler.
\item What alternative approaches are there to implement it?

Do we do this in an early stage, or at a later stage in the compiler.
\item How do we know which approach is more efficient?

What metric would be suitable to evaluate the different approaches with each other and with the legacy compiler.
\end{enumerate}



%Deelvragen:
% - Hoe impl. ik expl. in LLVM
% - Wat zijn de stappen
% - Alternatieven aanpakken
% - Hoe weet ik welke beter is
% - Hoe is dat nuttig voor andere architecture


%Overview
\section{Overview}\label{sec:overview}
In the remainder of this report we will discuss related works in Chapter \ref{chapter:related_work}. We will discuss bypassing, and show the difference between implicit and explicit bypassing in Chapter \ref{chapter:explicit_bypassing}. Proposed solutions for how to achieve our goal will be discussed in Chapter \ref{chapter:solutions} and we will discuss on how to evaluate each of the proposed solutions in Chapter \ref{chapter:evaluation}. Preliminary conclusions are given in Section \ref{chapter:conclusions} and we will provide a planning for this master thesis in Chapter \ref{chapter:planning}.